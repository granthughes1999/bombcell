{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retroactive ROI labels for Phy (IN_ROI / OUT_ROI)\n",
    "\n",
    "Use this notebook to write `cluster_bc_roiLabel.tsv` into existing Kilosort folders **without rerunning Bombcell**.\n",
    "Phy can then show `bc_roiLabel` in ClusterView after reopening the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bombcell as bc\n",
    "\n",
    "sys.path.insert(0, str((Path.cwd() / '..' / '..').resolve()))\n",
    "from grant.grant_config import load_grant_config\n",
    "\n",
    "CONFIG_FILE = Path('../configs/grant_recording_config.json')\n",
    "PROBES_TO_PROCESS = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "ROI_END_UM_OVERRIDE = {}  # example: {'B': 950}\n",
    "KS_DIR_OVERRIDE_BY_PROBE = {}  # example: {'B': Path(r'D:/.../kilosort4_B')}\n",
    "TIP_POSITION = 'min_y'  # 'min_y' or 'max_y'\n",
    "DRY_RUN = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_grant_config(CONFIG_FILE)\n",
    "print('Loaded config:', cfg['config_path'])\n",
    "print('Recording:', cfg['recording_name'])\n",
    "\n",
    "def resolve_ks_dir(probe):\n",
    "    probe = probe.upper()\n",
    "    if probe in KS_DIR_OVERRIDE_BY_PROBE:\n",
    "        return Path(KS_DIR_OVERRIDE_BY_PROBE[probe])\n",
    "    return Path(cfg['probe_kilosort_dirs'][probe])\n",
    "\n",
    "def resolve_roi_end_um(probe):\n",
    "    probe = probe.upper()\n",
    "    if probe in ROI_END_UM_OVERRIDE:\n",
    "        return ROI_END_UM_OVERRIDE[probe]\n",
    "    return cfg.get('probe_recording_roi', {}).get(probe)\n",
    "\n",
    "def load_quality_metrics_table(ks_dir):\n",
    "    parquet_path = ks_dir / 'bombcell' / 'templates._bc_qMetrics.parquet'\n",
    "    csv_path = ks_dir / 'metrics.csv'\n",
    "    if parquet_path.exists():\n",
    "        return pd.read_parquet(parquet_path), parquet_path\n",
    "    if csv_path.exists():\n",
    "        return pd.read_csv(csv_path), csv_path\n",
    "    raise FileNotFoundError(\n",
    "        f'Could not find quality metrics in {ks_dir}. Expected either {parquet_path.name} or {csv_path.name}.'\n",
    "    )\n",
    "\n",
    "def compute_roi_labels(quality_metrics_df, ks_dir, roi_end_um, tip_position='min_y', in_label='IN_ROI', out_label='OUT_ROI'):\n",
    "    if 'maxChannels' not in quality_metrics_df.columns:\n",
    "        raise KeyError(\"quality metrics table must include 'maxChannels'.\")\n",
    "\n",
    "    ephys_data = bc.load_ephys_data(str(ks_dir))\n",
    "    channel_positions = ephys_data[6]\n",
    "    shank_y = channel_positions[:, 1].astype(float)\n",
    "\n",
    "    max_channels = quality_metrics_df['maxChannels'].astype(int).to_numpy()\n",
    "    if np.any(max_channels < 0) or np.any(max_channels >= len(channel_positions)):\n",
    "        raise IndexError(f'maxChannels out of range for {ks_dir}')\n",
    "\n",
    "    unit_y = channel_positions[max_channels, 1].astype(float)\n",
    "    if tip_position == 'min_y':\n",
    "        dist_um = unit_y - float(np.nanmin(shank_y))\n",
    "    elif tip_position == 'max_y':\n",
    "        dist_um = float(np.nanmax(shank_y)) - unit_y\n",
    "    else:\n",
    "        raise ValueError(\"tip_position must be 'min_y' or 'max_y'.\")\n",
    "\n",
    "    return np.where(dist_um <= float(roi_end_um), in_label, out_label)\n",
    "\n",
    "def resolve_cluster_ids(quality_metrics_df):\n",
    "    if 'phy_clusterID' in quality_metrics_df.columns:\n",
    "        return quality_metrics_df['phy_clusterID'].astype(int).to_numpy()\n",
    "    if 'cluster_id' in quality_metrics_df.columns:\n",
    "        return quality_metrics_df['cluster_id'].astype(int).to_numpy()\n",
    "    raise KeyError(\"Could not find cluster IDs. Expected 'phy_clusterID' or 'cluster_id' in quality metrics table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for probe in [p.upper() for p in PROBES_TO_PROCESS]:\n",
    "    ks_dir = resolve_ks_dir(probe)\n",
    "    roi_end_um = resolve_roi_end_um(probe)\n",
    "\n",
    "    if roi_end_um is None:\n",
    "        print(f'Skipping probe {probe}: ROI not set in config and no override provided.')\n",
    "        results.append({'probe': probe, 'status': 'SKIPPED_ROI_NOT_SET', 'ks_dir': str(ks_dir)})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        qm_df, qm_source = load_quality_metrics_table(ks_dir)\n",
    "        cluster_ids = resolve_cluster_ids(qm_df)\n",
    "        roi_labels = compute_roi_labels(qm_df, ks_dir, roi_end_um=roi_end_um, tip_position=TIP_POSITION)\n",
    "\n",
    "        if len(cluster_ids) != len(roi_labels):\n",
    "            raise ValueError(\n",
    "                f'cluster_ids length ({len(cluster_ids)}) != roi_labels length ({len(roi_labels)}) for probe {probe}'\n",
    "            )\n",
    "\n",
    "        out_tsv = ks_dir / 'cluster_bc_roiLabel.tsv'\n",
    "        out_df = pd.DataFrame({'cluster_id': cluster_ids, 'bc_roiLabel': roi_labels})\n",
    "\n",
    "        if not DRY_RUN:\n",
    "            out_df.to_csv(out_tsv, sep='\\t', index=False)\n",
    "\n",
    "        counts = out_df['bc_roiLabel'].value_counts().to_dict()\n",
    "        print(f\"Probe {probe}: {'would write' if DRY_RUN else 'wrote'} {out_tsv}\")\n",
    "        print(f'  Source quality metrics: {qm_source}')\n",
    "        print(f'  Counts: {counts}')\n",
    "\n",
    "        results.append({\n",
    "            'probe': probe,\n",
    "            'status': 'DRY_RUN' if DRY_RUN else 'WROTE',\n",
    "            'ks_dir': str(ks_dir),\n",
    "            'quality_metrics_source': str(qm_source),\n",
    "            'roi_end_um': float(roi_end_um),\n",
    "            'n_clusters': int(len(out_df)),\n",
    "            'n_in_roi': int((out_df['bc_roiLabel'] == 'IN_ROI').sum()),\n",
    "            'n_out_roi': int((out_df['bc_roiLabel'] == 'OUT_ROI').sum()),\n",
    "        })\n",
    "    except Exception as exc:\n",
    "        print(f'Probe {probe}: ERROR -> {exc}')\n",
    "        results.append({'probe': probe, 'status': 'ERROR', 'ks_dir': str(ks_dir), 'error': str(exc)})\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step in Phy\n",
    "After writing `cluster_bc_roiLabel.tsv`, reopen the dataset in Phy.\n",
    "You should be able to show the `bc_roiLabel` column in ClusterView.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
