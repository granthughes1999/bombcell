{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bombcell Post-Run Analysis (Open Ephys + Kilosort4)\n",
        "\n",
        "Assumes Bombcell has already been run and you exported per-probe CSV/JSON summaries.\n",
        "\n",
        "**Expected folder convention**\n",
        "- `{NP_recording_name}/bombcell_DEFAULT/`\n",
        "  - `DUPLICATED_KILOSORT4_FILES/`\n",
        "  - `batch_DEFAULT_results/`\n",
        "- `{NP_recording_name}/bombcell_NP2.0/`\n",
        "  - `DUPLICATED_KILOSORT4_FILES_ACD/`\n",
        "  - `NP2_ReRun_results/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Configure\n",
        "# =========================\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "NP_recording_name = \"Reach15_20260201_session007_NP_Recording_Number02_2026-02-01_18-25-00\"  # <-- edit\n",
        "\n",
        "BASE_ROOT = Path(r\"H:\\Grant\\Neuropixels\\Kilosort_Recordings\")\n",
        "RECORDING_ROOT = BASE_ROOT / NP_recording_name\n",
        "\n",
        "DEFAULT_EXPORT_ROOT = RECORDING_ROOT / \"bombcell_DEFAULT\" / \"batch_DEFAULT_results\"\n",
        "NP20_EXPORT_ROOT    = RECORDING_ROOT / \"bombcell_NP2.0\" / \"NP2_ReRun_results\"\n",
        "\n",
        "PROBES_ALL  = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
        "PROBES_NP20 = [\"A\",\"C\",\"D\"]\n",
        "\n",
        "print(\"RECORDING_ROOT:\", RECORDING_ROOT)\n",
        "print(\"DEFAULT_EXPORT_ROOT exists:\", DEFAULT_EXPORT_ROOT.exists())\n",
        "print(\"NP20_EXPORT_ROOT exists:\", NP20_EXPORT_ROOT.exists())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def load_probe_exports(export_root: Path, probe: str):\n",
        "    # Loads Probe_{probe} exports: quality_metrics.csv, unit_type_counts.csv, param.json, checks.json.\n",
        "    probe_dir = export_root / f\"Probe_{probe}\"\n",
        "    qm_path = probe_dir / f\"Probe_{probe}_quality_metrics.csv\"\n",
        "    counts_path = probe_dir / f\"Probe_{probe}_unit_type_counts.csv\"\n",
        "    param_path = probe_dir / f\"Probe_{probe}_param.json\"\n",
        "    checks_path = probe_dir / f\"Probe_{probe}_checks.json\"\n",
        "    err_path = probe_dir / \"ERROR.txt\"\n",
        "\n",
        "    if err_path.exists():\n",
        "        return {\"probe\": probe, \"status\": \"FAILED\", \"error\": err_path.read_text(), \"probe_dir\": probe_dir}\n",
        "\n",
        "    out = {\"probe\": probe, \"status\": \"OK\", \"probe_dir\": probe_dir}\n",
        "    out[\"qm\"] = pd.read_csv(qm_path) if qm_path.exists() else None\n",
        "    out[\"counts\"] = pd.read_csv(counts_path) if counts_path.exists() else None\n",
        "    out[\"param\"] = json.loads(param_path.read_text()) if param_path.exists() else {}\n",
        "    out[\"checks\"] = json.loads(checks_path.read_text()) if checks_path.exists() else {}\n",
        "\n",
        "    out[\"cluster_id_col\"] = None\n",
        "    if out[\"qm\"] is not None:\n",
        "        for c in [\"cluster_id\",\"clusterID\",\"cluster_id_ks\",\"cluster_id_phy\",\"cluster\"]:\n",
        "            if c in out[\"qm\"].columns:\n",
        "                out[\"cluster_id_col\"] = c\n",
        "                break\n",
        "\n",
        "    return out\n",
        "\n",
        "def load_batch_summary(export_root: Path):\n",
        "    p = export_root / \"batch_summary.csv\"\n",
        "    return pd.read_csv(p) if p.exists() else None\n",
        "\n",
        "def summarize_unit_types(qm: pd.DataFrame, label_col=\"Bombcell_unit_type\"):\n",
        "    if qm is None or label_col not in qm.columns:\n",
        "        return None\n",
        "    return qm[label_col].value_counts().rename_axis(\"unit_type\").reset_index(name=\"count\")\n",
        "\n",
        "def add_percentages(df_counts: pd.DataFrame):\n",
        "    if df_counts is None or df_counts.empty:\n",
        "        return df_counts\n",
        "    total = df_counts[\"count\"].sum()\n",
        "    df_counts = df_counts.copy()\n",
        "    df_counts[\"pct\"] = 100 * df_counts[\"count\"] / total\n",
        "    return df_counts\n",
        "\n",
        "def find_cluster_row(qm: pd.DataFrame, cluster_id: int, cluster_id_col: str):\n",
        "    if qm is None:\n",
        "        raise ValueError(\"qm is None\")\n",
        "    if cluster_id_col is None or cluster_id_col not in qm.columns:\n",
        "        raise ValueError(\"No cluster_id column found in quality_metrics.csv\")\n",
        "    sub = qm.loc[qm[cluster_id_col] == cluster_id]\n",
        "    if sub.empty:\n",
        "        raise KeyError(f\"Cluster id {cluster_id} not found in {cluster_id_col}\")\n",
        "    return sub.iloc[0]\n",
        "\n",
        "def threshold_fail_report(row, qm_cols, param):\n",
        "    # Common Bombcell gates; only checks metrics that exist in the CSV.\n",
        "    rules = [\n",
        "        (\"rawAmplitude\", \"<\", param.get(\"minAmplitude\", 40)),\n",
        "        (\"signalToNoiseRatio\", \"<\", param.get(\"minSNR\", 5)),\n",
        "        (\"presenceRatio\", \"<\", param.get(\"minPresenceRatio\", 0.7)),\n",
        "        (\"fractionRPVs_estimatedTauR\", \">\", param.get(\"maxRPVviolations\", 0.1)),\n",
        "        (\"percentageSpikesMissing_gaussian\", \">\", param.get(\"maxPercSpikesMissing\", 20)),\n",
        "        (\"waveformDuration_peakTrough\", \"<\", param.get(\"minWvDuration\", 100)),\n",
        "        (\"waveformDuration_peakTrough\", \">\", param.get(\"maxWvDuration\", 1150)),\n",
        "        (\"nPeaks\", \">\", param.get(\"maxNPeaks\", 2)),\n",
        "        (\"nTroughs\", \">\", param.get(\"maxNTroughs\", 1)),\n",
        "        (\"waveformBaselineFlatness\", \">\", param.get(\"maxWvBaselineFraction\", 0.3)),\n",
        "    ]\n",
        "    fails = []\n",
        "    for col, op, thr in rules:\n",
        "        if col not in qm_cols:\n",
        "            continue\n",
        "        v = row[col]\n",
        "        if pd.isna(v):\n",
        "            continue\n",
        "        if (op == \"<\" and v < thr) or (op == \">\" and v > thr):\n",
        "            fails.append((col, float(v), op, float(thr)))\n",
        "    return fails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load DEFAULT exports (all probes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "default_summary = load_batch_summary(DEFAULT_EXPORT_ROOT)\n",
        "default_summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "default_data = {p: load_probe_exports(DEFAULT_EXPORT_ROOT, p) for p in PROBES_ALL}\n",
        "\n",
        "for p in PROBES_ALL:\n",
        "    d = default_data[p]\n",
        "    print(\"=\"*60, f\"Probe {p} ({d['status']})\")\n",
        "    if d[\"status\"] != \"OK\":\n",
        "        print(d.get(\"error\",\"\"))\n",
        "        continue\n",
        "    counts = add_percentages(summarize_unit_types(d[\"qm\"]))\n",
        "    display(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load NP2.0 rerun exports (A/C/D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "np20_summary = load_batch_summary(NP20_EXPORT_ROOT)\n",
        "np20_summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "np20_data = {p: load_probe_exports(NP20_EXPORT_ROOT, p) for p in PROBES_NP20}\n",
        "\n",
        "for p in PROBES_NP20:\n",
        "    d = np20_data[p]\n",
        "    print(\"=\"*60, f\"Probe {p} ({d['status']})\")\n",
        "    if d[\"status\"] != \"OK\":\n",
        "        print(d.get(\"error\",\"\"))\n",
        "        continue\n",
        "    counts = add_percentages(summarize_unit_types(d[\"qm\"]))\n",
        "    display(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare DEFAULT vs NP2.0 rerun (A/C/D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "rows = []\n",
        "for p in PROBES_NP20:\n",
        "    d0 = default_data.get(p, {})\n",
        "    d1 = np20_data.get(p, {})\n",
        "    if d0.get(\"status\") != \"OK\" or d1.get(\"status\") != \"OK\":\n",
        "        continue\n",
        "\n",
        "    c0 = summarize_unit_types(d0[\"qm\"])\n",
        "    c1 = summarize_unit_types(d1[\"qm\"])\n",
        "\n",
        "    def _get(ct, name):\n",
        "        if ct is None: \n",
        "            return 0\n",
        "        sub = ct.loc[ct[\"unit_type\"] == name, \"count\"]\n",
        "        return int(sub.iloc[0]) if len(sub) else 0\n",
        "\n",
        "    rows.append({\n",
        "        \"probe\": p,\n",
        "        \"DEFAULT_GOOD\": _get(c0,\"GOOD\"),\n",
        "        \"RERUN_GOOD\": _get(c1,\"GOOD\"),\n",
        "        \"DEFAULT_MUA\": _get(c0,\"MUA\"),\n",
        "        \"RERUN_MUA\": _get(c1,\"MUA\"),\n",
        "        \"DEFAULT_NOISE\": _get(c0,\"NOISE\"),\n",
        "        \"RERUN_NOISE\": _get(c1,\"NOISE\"),\n",
        "        \"DEFAULT_NON-SOMA\": _get(c0,\"NON-SOMA\"),\n",
        "        \"RERUN_NON-SOMA\": _get(c1,\"NON-SOMA\"),\n",
        "        \"DEFAULT_TOTAL\": len(d0[\"qm\"]),\n",
        "        \"RERUN_TOTAL\": len(d1[\"qm\"]),\n",
        "    })\n",
        "pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drill-down: why Bombcell labeled a specific cluster as MUA (or not GOOD)\n",
        "\n",
        "This reports which thresholds are violated for a chosen `probe` and `cluster_id`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "probe = \"B\"          # <-- edit\n",
        "cluster_id = 39      # <-- edit\n",
        "run = \"DEFAULT\"      # \"DEFAULT\" or \"NP20\"\n",
        "\n",
        "d = default_data[probe] if run == \"DEFAULT\" else np20_data[probe]\n",
        "\n",
        "qm = d[\"qm\"]\n",
        "param = d[\"param\"]\n",
        "cluster_id_col = d.get(\"cluster_id_col\", None)\n",
        "\n",
        "print(\"Run:\", run)\n",
        "print(\"Probe:\", probe)\n",
        "print(\"cluster_id_col:\", cluster_id_col)\n",
        "\n",
        "row = find_cluster_row(qm, cluster_id, cluster_id_col)\n",
        "print(\"Bombcell label:\", row.get(\"Bombcell_unit_type\", \"UNKNOWN\"))\n",
        "\n",
        "fails = threshold_fail_report(row, qm.columns, param)\n",
        "\n",
        "print(\"\\n---- FAILING GATES ----\")\n",
        "if not fails:\n",
        "    print(\"No fails among common checks; expand rules or inspect full row.\")\n",
        "else:\n",
        "    for col, v, op, thr in fails:\n",
        "        print(f\"{col:35s} {v:>10.4f}  FAIL ({op}{thr})\")\n",
        "\n",
        "print(\"\\n---- Key values ----\")\n",
        "key_cols = [\n",
        "    \"rawAmplitude\",\"signalToNoiseRatio\",\"presenceRatio\",\n",
        "    \"fractionRPVs_estimatedTauR\",\"percentageSpikesMissing_gaussian\",\n",
        "    \"waveformDuration_peakTrough\",\"nPeaks\",\"nTroughs\",\"waveformBaselineFlatness\"\n",
        "]\n",
        "for c in key_cols:\n",
        "    if c in qm.columns:\n",
        "        print(f\"{c:35s} {row[c]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distributions (RPV, presenceRatio)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "probe = \"A\"      # <-- edit\n",
        "run = \"NP20\"     # \"DEFAULT\" or \"NP20\"\n",
        "\n",
        "d = default_data[probe] if run == \"DEFAULT\" else np20_data[probe]\n",
        "qm = d[\"qm\"]\n",
        "\n",
        "for col in [\"fractionRPVs_estimatedTauR\", \"presenceRatio\"]:\n",
        "    if col in qm.columns:\n",
        "        plt.figure()\n",
        "        plt.hist(qm[col].dropna(), bins=50)\n",
        "        plt.title(f\"{probe} {run}: {col}\")\n",
        "        plt.xlabel(col); plt.ylabel(\"count\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric-by-label medians"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "probe = \"A\"      # <-- edit\n",
        "run = \"NP20\"     # \"DEFAULT\" or \"NP20\"\n",
        "\n",
        "d = default_data[probe] if run == \"DEFAULT\" else np20_data[probe]\n",
        "qm = d[\"qm\"]\n",
        "\n",
        "metrics = [\"fractionRPVs_estimatedTauR\",\"presenceRatio\",\"rawAmplitude\",\"signalToNoiseRatio\"]\n",
        "present = [m for m in metrics if m in qm.columns]\n",
        "qm.groupby(\"Bombcell_unit_type\")[present].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compact overview table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def overview_table(data_dict: dict):\n",
        "    rows = []\n",
        "    for p, d in data_dict.items():\n",
        "        if d.get(\"status\") != \"OK\":\n",
        "            rows.append({\"probe\": p, \"status\": \"FAILED\"})\n",
        "            continue\n",
        "        qm = d[\"qm\"]\n",
        "        counts = qm[\"Bombcell_unit_type\"].value_counts()\n",
        "        total = len(qm)\n",
        "        row = {\n",
        "            \"probe\": p,\n",
        "            \"status\": \"OK\",\n",
        "            \"n_total\": int(total),\n",
        "            \"n_GOOD\": int(counts.get(\"GOOD\",0)),\n",
        "            \"pct_GOOD\": 100*float(counts.get(\"GOOD\",0))/total if total else np.nan,\n",
        "        }\n",
        "        for m in [\"fractionRPVs_estimatedTauR\",\"presenceRatio\",\"rawAmplitude\",\"signalToNoiseRatio\"]:\n",
        "            if m in qm.columns:\n",
        "                row[f\"median_{m}\"] = float(qm[m].median())\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "default_overview = overview_table(default_data)\n",
        "np20_overview = overview_table(np20_data)\n",
        "\n",
        "print(\"DEFAULT overview\")\n",
        "display(default_overview.sort_values(\"probe\"))\n",
        "\n",
        "print(\"NP2.0 rerun overview\")\n",
        "display(np20_overview.sort_values(\"probe\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}