{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Classification Reason to Phy\n",
    "\n",
    "This notebook extracts the main classification reason for each unit from Bombcell results and exports it as a TSV file that can be viewed in Phy's cluster view tab.\n",
    "\n",
    "The classification reason shows why each unit was classified as GOOD, NOISE, MUA, or NON-SOMA.\n",
    "\n",
    "## Usage:\n",
    "1. Set the configuration parameters below (RUN_MODE, TARGET_PROBE, etc.)\n",
    "2. Run all cells\n",
    "3. The notebook will create a `cluster_bc_classificationReason.tsv` file in your Kilosort directory\n",
    "4. Open the data in Phy - you'll see a new \"bc_classificationReason\" column in the cluster view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - CHANGE THESE VALUES FOR YOUR DATA\n",
    "CONFIG_FILE = r'C:\\Users\\user\\Documents\\github\\bombcell\\py_bombcell\\grant\\configs\\grant_recording_config_reach15_20260201_session007.json'\n",
    "RUN_MODE = 'single_probe'  # 'batch', 'single_probe', or 'np20_rerun'\n",
    "TARGET_PROBE = 'E'  # Only used for single_probe mode\n",
    "\n",
    "# Optional: Set to True to see detailed information about each unit's classification\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add parent directory to path for grant_config import\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from grant_config import load_grant_config\n",
    "\n",
    "import bombcell as bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "cfg = load_grant_config(CONFIG_FILE)\n",
    "\n",
    "# Determine staging root based on run mode\n",
    "if RUN_MODE == 'batch':\n",
    "    staging_root = cfg['default_ks_staging_root']\n",
    "elif RUN_MODE == 'np20_rerun':\n",
    "    staging_root = cfg['np20_ks_staging_root']\n",
    "else:  # single_probe\n",
    "    staging_root = cfg['bombcell_singleprobe_root']\n",
    "\n",
    "# Build paths\n",
    "ks_dir = Path(staging_root) / f'kilosort4_{TARGET_PROBE}'\n",
    "save_path = ks_dir / 'bombcell'\n",
    "\n",
    "print('Kilosort directory:', ks_dir)\n",
    "print('Bombcell save path:', save_path)\n",
    "print()\n",
    "print('TSV file will be saved to:', ks_dir / 'cluster_bc_classificationReason.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bombcell Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bombcell results\n",
    "param, quality_metrics, _ = bc.load_bc_results(str(save_path))\n",
    "\n",
    "# Get unit classifications\n",
    "unit_type, unit_type_string = bc.qm.get_quality_unit_type(param, quality_metrics)\n",
    "\n",
    "# Create DataFrame\n",
    "qm_df = pd.DataFrame(quality_metrics).copy()\n",
    "qm_df['bombcell_label'] = unit_type_string\n",
    "qm_df['unit_index'] = np.arange(len(qm_df))\n",
    "\n",
    "# Get cluster IDs\n",
    "if 'cluster_id' not in qm_df.columns:\n",
    "    if 'unique_templates' in param:\n",
    "        qm_df['cluster_id'] = param['unique_templates']\n",
    "    elif 'phy_clusterID' in quality_metrics:\n",
    "        qm_df['cluster_id'] = quality_metrics['phy_clusterID']\n",
    "    else:\n",
    "        qm_df['cluster_id'] = qm_df['unit_index']\n",
    "\n",
    "print(f'Loaded {len(qm_df)} units')\n",
    "print('\\nLabel distribution:')\n",
    "print(qm_df['bombcell_label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classification Reason Extraction Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col(name):\n",
    "    \"\"\"Helper function to safely get column from DataFrame\"\"\"\n",
    "    if name in qm_df.columns:\n",
    "        return qm_df[name]\n",
    "    return pd.Series(np.nan, index=qm_df.index)\n",
    "\n",
    "# Define NOISE failure conditions\n",
    "noise_fail = {\n",
    "    'nPeaks>maxNPeaks': col('nPeaks') > param['maxNPeaks'],\n",
    "    'nTroughs>maxNTroughs': col('nTroughs') > param['maxNTroughs'],\n",
    "    'wvDuration<minWvDuration': col('waveformDuration_peakTrough') < param['minWvDuration'],\n",
    "    'wvDuration>maxWvDuration': col('waveformDuration_peakTrough') > param['maxWvDuration'],\n",
    "    'baselineFlatness>maxWvBaselineFraction': col('waveformBaselineFlatness') > param['maxWvBaselineFraction'],\n",
    "    'scndPeakToTroughRatio>maxScndPeakToTroughRatio_noise': col('scndPeakToTroughRatio') > param['maxScndPeakToTroughRatio_noise'],\n",
    "}\n",
    "\n",
    "# Add spatial decay checks if computed\n",
    "if bool(param.get('computeSpatialDecay', False)):\n",
    "    if bool(param.get('spDecayLinFit', False)):\n",
    "        noise_fail['spatialDecaySlope<minSpatialDecaySlope'] = col('spatialDecaySlope') < param['minSpatialDecaySlope']\n",
    "    else:\n",
    "        noise_fail['spatialDecaySlope<minSpatialDecaySlopeExp'] = col('spatialDecaySlope') < param['minSpatialDecaySlopeExp']\n",
    "        noise_fail['spatialDecaySlope>maxSpatialDecaySlopeExp'] = col('spatialDecaySlope') > param['maxSpatialDecaySlopeExp']\n",
    "\n",
    "# Define MUA failure conditions\n",
    "mua_fail = {\n",
    "    'percentageSpikesMissing_gaussian>maxPercSpikesMissing': col('percentageSpikesMissing_gaussian') > param['maxPercSpikesMissing'],\n",
    "    'nSpikes<minNumSpikes': col('nSpikes') < param['minNumSpikes'],\n",
    "    'fractionRPVs_estimatedTauR>maxRPVviolations': col('fractionRPVs_estimatedTauR') > param['maxRPVviolations'],\n",
    "    'presenceRatio<minPresenceRatio': col('presenceRatio') < param['minPresenceRatio'],\n",
    "}\n",
    "\n",
    "# Add raw waveform checks if computed\n",
    "if bool(param.get('extractRaw', False)):\n",
    "    mua_fail['rawAmplitude<minAmplitude'] = col('rawAmplitude') < param['minAmplitude']\n",
    "    mua_fail['signalToNoiseRatio<minSNR'] = col('signalToNoiseRatio') < param['minSNR']\n",
    "\n",
    "# Add drift checks if computed\n",
    "if bool(param.get('computeDrift', False)):\n",
    "    mua_fail['maxDriftEstimate>maxDrift'] = col('maxDriftEstimate') > param['maxDrift']\n",
    "\n",
    "# Add distance metric checks if computed\n",
    "if bool(param.get('computeDistanceMetrics', False)):\n",
    "    mua_fail['isolationDistance<isoDmin'] = col('isolationDistance') < param['isoDmin']\n",
    "    mua_fail['Lratio>lratioMax'] = col('Lratio') > param['lratioMax']\n",
    "\n",
    "# Define NON-SOMA failure conditions\n",
    "non_soma_fail = {\n",
    "    'troughToPeak2Ratio<minTroughToPeak2Ratio_nonSomatic': col('troughToPeak2Ratio') < param['minTroughToPeak2Ratio_nonSomatic'],\n",
    "    'mainPeak_before_width<minWidthFirstPeak_nonSomatic': col('mainPeak_before_width') < param['minWidthFirstPeak_nonSomatic'],\n",
    "    'mainTrough_width<minWidthMainTrough_nonSomatic': col('mainTrough_width') < param['minWidthMainTrough_nonSomatic'],\n",
    "    'peak1ToPeak2Ratio>maxPeak1ToPeak2Ratio_nonSomatic': col('peak1ToPeak2Ratio') > param['maxPeak1ToPeak2Ratio_nonSomatic'],\n",
    "    'mainPeakToTroughRatio>maxMainPeakToTroughRatio_nonSomatic': col('mainPeakToTroughRatio') > param['maxMainPeakToTroughRatio_nonSomatic'],\n",
    "}\n",
    "\n",
    "print('Defined classification rules:')\n",
    "print(f'  NOISE: {len(noise_fail)} criteria')\n",
    "print(f'  MUA: {len(mua_fail)} criteria')\n",
    "print(f'  NON-SOMA: {len(non_soma_fail)} criteria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Classification Reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for faster processing\n",
    "noise_fail_np = {k: np.asarray(v, dtype=bool) for k, v in noise_fail.items()}\n",
    "mua_fail_np = {k: np.asarray(v, dtype=bool) for k, v in mua_fail.items()}\n",
    "nonsoma_fail_np = {k: np.asarray(v, dtype=bool) for k, v in non_soma_fail.items()}\n",
    "labels_np = qm_df['bombcell_label'].astype(str).to_numpy()\n",
    "\n",
    "def get_main_reason(i: int) -> str:\n",
    "    \"\"\"\n",
    "    Get the main (first) classification reason for a unit.\n",
    "    \n",
    "    Returns the primary reason why the unit was classified as NOISE, MUA, NON-SOMA, or GOOD.\n",
    "    \"\"\"\n",
    "    label = labels_np[i]\n",
    "    \n",
    "    # Find which criteria failed for this unit\n",
    "    noise_hits = [k for k, v in noise_fail_np.items() if bool(v[i])]\n",
    "    mua_hits = [k for k, v in mua_fail_np.items() if bool(v[i])]\n",
    "    nonsoma_hits = [k for k, v in nonsoma_fail_np.items() if bool(v[i])]\n",
    "    \n",
    "    # Return the first (main) reason based on the label\n",
    "    if label == 'NOISE':\n",
    "        if noise_hits:\n",
    "            return f'NOISE: {noise_hits[0]}'\n",
    "        return 'NOISE'\n",
    "    \n",
    "    elif label in ('MUA', 'NON-SOMA MUA'):\n",
    "        if mua_hits:\n",
    "            return f'MUA: {mua_hits[0]}'\n",
    "        return 'MUA'\n",
    "    \n",
    "    elif label in ('NON-SOMA', 'NON-SOMA GOOD'):\n",
    "        if nonsoma_hits:\n",
    "            return f'NON-SOMA: {nonsoma_hits[0]}'\n",
    "        return 'NON-SOMA'\n",
    "    \n",
    "    elif label == 'GOOD':\n",
    "        return 'GOOD: passed all thresholds'\n",
    "    \n",
    "    else:\n",
    "        return f'{label}'\n",
    "\n",
    "def get_all_reasons(i: int) -> str:\n",
    "    \"\"\"\n",
    "    Get all classification reasons for a unit (for verbose output).\n",
    "    \n",
    "    Returns all reasons separated by ' | '.\n",
    "    \"\"\"\n",
    "    label = labels_np[i]\n",
    "    reasons = []\n",
    "\n",
    "    noise_hits = [k for k, v in noise_fail_np.items() if bool(v[i])]\n",
    "    mua_hits = [k for k, v in mua_fail_np.items() if bool(v[i])]\n",
    "    nonsoma_hits = [k for k, v in nonsoma_fail_np.items() if bool(v[i])]\n",
    "\n",
    "    if label == 'NOISE':\n",
    "        reasons.extend([f'NOISE: {r}' for r in noise_hits] or ['NOISE'])\n",
    "    elif label in ('MUA', 'NON-SOMA MUA'):\n",
    "        reasons.extend([f'MUA: {r}' for r in mua_hits] or ['MUA'])\n",
    "    elif label in ('NON-SOMA', 'NON-SOMA GOOD'):\n",
    "        reasons.extend([f'NON-SOMA: {r}' for r in nonsoma_hits] or ['NON-SOMA'])\n",
    "\n",
    "    if label == 'GOOD':\n",
    "        reasons.append('GOOD: passed all thresholds')\n",
    "\n",
    "    return ' | '.join(reasons) if reasons else label\n",
    "\n",
    "# Extract main reason for each unit\n",
    "qm_df['main_reason'] = [get_main_reason(i) for i in range(len(qm_df))]\n",
    "\n",
    "print('Classification reasons extracted!')\n",
    "print(f'\\nExample reasons (first 5 units):')\n",
    "for i in range(min(5, len(qm_df))):\n",
    "    print(f\"  Unit {i} ({labels_np[i]}): {qm_df['main_reason'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Classification Reason Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of main reasons\n",
    "print('Main reason distribution:')\n",
    "print(qm_df['main_reason'].value_counts())\n",
    "print()\n",
    "\n",
    "# Show example units for each label type\n",
    "if VERBOSE:\n",
    "    print('\\n' + '='*80)\n",
    "    print('DETAILED VIEW: Example units for each classification')\n",
    "    print('='*80)\n",
    "    \n",
    "    for label in ['GOOD', 'NOISE', 'MUA', 'NON-SOMA', 'NON-SOMA GOOD', 'NON-SOMA MUA']:\n",
    "        subset = qm_df[qm_df['bombcell_label'] == label]\n",
    "        if len(subset) > 0:\n",
    "            print(f'\\n{label} units (showing up to 3 examples):')\n",
    "            for idx in subset.index[:3]:\n",
    "                cluster_id = qm_df.loc[idx, 'cluster_id']\n",
    "                main_reason = qm_df.loc[idx, 'main_reason']\n",
    "                all_reasons = get_all_reasons(idx)\n",
    "                print(f'  Cluster {cluster_id}:')\n",
    "                print(f'    Main: {main_reason}')\n",
    "                if ' | ' in all_reasons:\n",
    "                    print(f'    All:  {all_reasons}')\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Phy TSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TSV file for Phy\n",
    "output_file = ks_dir / 'cluster_bc_classificationReason.tsv'\n",
    "\n",
    "# Create DataFrame with cluster_id and classification reason\n",
    "export_df = pd.DataFrame({\n",
    "    'cluster_id': qm_df['cluster_id'].astype(int),\n",
    "    'bc_classificationReason': qm_df['main_reason']\n",
    "})\n",
    "\n",
    "# Save as TSV\n",
    "export_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f'âœ“ Successfully exported classification reasons to:')\n",
    "print(f'  {output_file}')\n",
    "print()\n",
    "print(f'Exported {len(export_df)} units')\n",
    "print()\n",
    "print('To view in Phy:')\n",
    "print('  1. Open your data in Phy')\n",
    "print('  2. Look for the \"bc_classificationReason\" column in the cluster view')\n",
    "print('  3. You can sort and filter by this column to explore classification reasons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Exported Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows of exported data\n",
    "print('Preview of exported TSV file (first 10 rows):')\n",
    "print(export_df.head(10))\n",
    "print()\n",
    "print('Preview of exported TSV file (last 10 rows):')\n",
    "print(export_df.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
